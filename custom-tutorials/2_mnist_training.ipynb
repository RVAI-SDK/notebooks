{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RVAI Training Example\n",
    "In this example we will train an ImageClassifierCell (which wraps a small convolutional neural net) on the Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "First, let's install all the prerequisites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qqq rvai==0.6.0rc2 pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global notebook configuration\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a TrainableCell\n",
    "Okay, let's create a cell. A cell can can be used as building block in a computation DAG - called a Pipeline in RVAI. Since our Cell should also be trainable, we select the `TrainableCell` base class.\n",
    "The basic skeleton of a `TrainableCell` can be found in the [docs [1]](https://base.rvai.dev/rvai.base.html#rvai.base.cell.TrainableCell). It tells us that we need a `load_model`, `predict`, `test` and `train` method. For the sake of this tutorial we will only implement `load_model` and `train` however. Testing and inference will be discussed in a subsequent tutorial.\n",
    "\n",
    "### Cell IO\n",
    "\n",
    "But before we start implementing these methods, we should think about the required IO 'ports' of our Cell first. What are the Inputs and the Ouputs of this building block? What kind of example data does the training need? Let's describe that first in code. RVAI uses [dataclasses [2]](https://docs.python.org/3/library/dataclasses.html) as a mechanism to encode that information in a convenient struct.\n",
    "\n",
    "- [1] https://base.rvai.dev/rvai.base.html#rvai.base.cell.TrainableCell (WIP)\n",
    "- [2] https://docs.python.org/3/library/dataclasses.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "# base classes for the structs used to describe a Cell's IO\n",
    "from rvai.base.data import Inputs, Outputs, Samples, Annotations, Parameters, metadata\n",
    "\n",
    "# some RVAI types we need for describing the fields of these IO dataclasses\n",
    "from rvai.types import Image, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference mode IO\n",
    "\n",
    "@dataclass\n",
    "class ImageClassificationInputs(Inputs):\n",
    "    image: Image = field(metadata=\n",
    "        metadata(name=\"Image\", description=\"The image to be classified.\"))\n",
    "\n",
    "@dataclass\n",
    "class ImageClassificationOutputs(Outputs):\n",
    "    label: Integer = field(\n",
    "        metadata=metadata(name=\"Class\", description=\"The class of the image.\"))\n",
    "\n",
    "# Training mode IO\n",
    "        \n",
    "@dataclass\n",
    "class ImageClassificationSamples(Samples, ImageClassificationInputs):\n",
    "    \"\"\"Inherits from ImageClassificationInputs because the Samples this Cell expects during training are the same as its inputs.\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class ImageClassificationAnnotations(Annotations, ImageClassificationOutputs):\n",
    "    \"\"\"Inherits from ImageClassificationOutputs because the Annotations this Cell expects during training are the same as its outputs.\"\"\"\n",
    "    \n",
    "# Parameters\n",
    "\n",
    "@dataclass\n",
    "class ImageClassificationParameters(Parameters):\n",
    "    epochs: Integer = field(default=Integer(2), metadata=metadata(name=\"Epochs\", description=\"The amount of times the training loop should process the data.\"))\n",
    "    batch_size: Integer = field(default=Integer(4), metadata=metadata(name=\"Batch Size\", description=\"SGD mini-batch size.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now go over the declared IO dataclasses in more detail.\n",
    "\n",
    "During inference, the Cell will have:\n",
    "- images in the form of `Images` going in\n",
    "- labels in the form of `Integers` going out\n",
    "\n",
    "During training, the Cell will:\n",
    "- receive examples in the form of an image (i.e. an `Image`) and a label (i.e. an `Integer`) going in\n",
    "\n",
    "The `Samples` and `Annotations` dataclasses inherit from `Inputs` en `Outputs` respectively. This is purely out of convenience and in a lot of cases the sample and annotation types will differ from their inference counterparts.\n",
    "\n",
    "Now, let's actually implement a TrainableCell!\n",
    "\n",
    "### Cell Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary RVAI imports:\n",
    "from rvai.base.cell import cell # used as a decorator to register a cell in RVAI\n",
    "from rvai.base.cell import TrainableCell # base class, defines main functionality\n",
    "\n",
    "# used for typing:\n",
    "from rvai.base.cell import CellMode # enum, defines what mode the cell is running in\n",
    "from rvai.base.data import Example, Dataset\n",
    "from rvai.base.context import Context # required argument for most cell methods, do not worry about this yet\n",
    "from typing import Type, Optional, Tuple, Sequence\n",
    "\n",
    "# dependencies used in the cell body itself:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.autograph.set_verbosity(1)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "from rvai.base import compat # convenience methods for integrating external ML framework (e.g. keras) code into RVAI\n",
    "from rvai.base.evaluation import CellEvaluationUpdate\n",
    "from rvai.base.training import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cell # used for registering the ImageClassificationCell in RVAI\n",
    "class ImageClassificationCell(TrainableCell):\n",
    "\n",
    "    # A Cell's IO is declared by using class attributes.\n",
    "    # These are the same dataclasses we defined before.\n",
    "    inputs: Type[ImageClassificationInputs]\n",
    "    outputs: Type[ImageClassificationOutputs]\n",
    "\n",
    "    samples: Type[ImageClassificationSamples]\n",
    "    annotations: Type[ImageClassificationAnnotations]\n",
    "\n",
    "    parameters: Type[ImageClassificationParameters]\n",
    "        \n",
    "    @classmethod\n",
    "    def load_model(\n",
    "        cls,\n",
    "        context: Context,\n",
    "        parameters: ImageClassificationParameters,\n",
    "        model_path: Optional[str],\n",
    "        mode: CellMode,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create or load a model.\n",
    "        \"\"\"        \n",
    "        if model_path is not None:\n",
    "            return tf.keras.models.load_model(model_path)\n",
    "        else:\n",
    "            model = tf.keras.Sequential()\n",
    "            model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "            model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "            model.add(tf.keras.layers.Dropout(0.3))\n",
    "            model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "            model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "            model.add(tf.keras.layers.Dropout(0.3))\n",
    "            model.add(tf.keras.layers.Flatten())\n",
    "            model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "            model.add(tf.keras.layers.Dropout(0.5))\n",
    "            model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def _unpack_example(\n",
    "        cls,\n",
    "        example: Example[ImageClassificationSamples, ImageClassificationAnnotations],\n",
    "    ) -> Tuple[np.ndarray, int]:\n",
    "        \"\"\"\n",
    "        Convert a RVAI Example into plain numpy/python data types.\n",
    "        \"\"\"\n",
    "\n",
    "        samples: ImageClassificationSamples = example[0]\n",
    "        annotations: ImageClassificationAnnotations = example[1]\n",
    "\n",
    "        # standardize image input\n",
    "        image = np.atleast_3d(samples.image)\n",
    "        label = int(annotations.label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    @classmethod\n",
    "    def _collate_batch(\n",
    "        cls,\n",
    "        examples: Sequence[Tuple[np.ndarray, np.ndarray]],\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Collate a bunch of unpacked Examples (see `_unpack_example`) into a batch format Keras understands.\n",
    "        \"\"\"\n",
    "        \n",
    "        x, y = zip(*examples)\n",
    "\n",
    "        images: np.ndarray = np.stack(arrays=x, axis=0)\n",
    "        labels: np.ndarray = tf.keras.utils.to_categorical(\n",
    "            y=y, num_classes=10, dtype=np.float32\n",
    "        )\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    @classmethod\n",
    "    def train(\n",
    "        cls,\n",
    "        context: Context,\n",
    "        parameters: ImageClassificationParameters,\n",
    "        model,\n",
    "        train_dataset: Dataset[\n",
    "            ImageClassificationSamples, ImageClassificationAnnotations\n",
    "        ],\n",
    "        validation_dataset: Dataset[\n",
    "            ImageClassificationSamples, ImageClassificationAnnotations\n",
    "        ],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Train a model on a Dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        # Integer -> int\n",
    "        batch_size = int(parameters.batch_size)\n",
    "\n",
    "        train_generator = compat.keras.as_generator(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            process_example=cls._unpack_example,\n",
    "            process_batch=cls._collate_batch,\n",
    "        )\n",
    "\n",
    "        validation_generator = compat.keras.as_generator(\n",
    "            validation_dataset,\n",
    "            batch_size=batch_size,\n",
    "            process_example=cls._unpack_example,\n",
    "            process_batch=cls._collate_batch,\n",
    "        )\n",
    "\n",
    "        nb_epochs = int(parameters.epochs)\n",
    "        nb_training_batches = int(len(train_dataset) // batch_size)\n",
    "        nb_validation_batches = int(len(validation_dataset) // batch_size)\n",
    "\n",
    "        model.fit_generator(\n",
    "            generator=train_generator,\n",
    "            steps_per_epoch=nb_training_batches,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_batches,\n",
    "            epochs=nb_epochs,\n",
    "            verbose=0,\n",
    "            callbacks=[compat.keras.training_update_callback(context)],\n",
    "        )\n",
    "\n",
    "        model_path = context.training.get_model_path()\n",
    "\n",
    "        tf.keras.models.save_model(model=model, filepath=model_path)\n",
    "\n",
    "        return model_path\n",
    "\n",
    "    @classmethod\n",
    "    def test(\n",
    "        cls,\n",
    "        context: Context,\n",
    "        parameters: ImageClassificationParameters,\n",
    "        model,\n",
    "        test_dataset: Dataset[\n",
    "            ImageClassificationSamples, ImageClassificationAnnotations\n",
    "        ],\n",
    "    ):\n",
    "        \n",
    "        batch_size = int(parameters.batch_size)\n",
    "        \n",
    "        test_generator = compat.keras.as_generator(\n",
    "            test_dataset,\n",
    "            batch_size=batch_size,\n",
    "            process_example=cls._unpack_example,\n",
    "            process_batch=cls._collate_batch,\n",
    "        )\n",
    "\n",
    "        nb_test_batches = int(len(test_dataset) // batch_size)\n",
    "    \n",
    "        metrics = model.evaluate_generator(\n",
    "            generator=test_generator,\n",
    "            steps=nb_test_batches,\n",
    "            verbose=0,\n",
    "        )\n",
    "        \n",
    "        return Metrics(\n",
    "            {name: metric for name, metric in zip(model.metrics_names, metrics)},\n",
    "            performance=\"acc\",\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def predict(\n",
    "        cls,\n",
    "        context: Context,\n",
    "        parameters: ImageClassificationParameters,\n",
    "        model,\n",
    "        inputs: ImageClassificationInputs,\n",
    "    ):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss.\n",
    "\n",
    "**the `load_model` method**\n",
    "\n",
    "The `load_model` method is fairly straightforward. It should always return a model object. RVAI does not care about what this model looks like. It will just pass whatever this method returns to all other methods that need a model (e.g. `TrainableCell::train`). This method also has an optional argument `model_path`. When a model path is given, it is expected from the `load_model` method that it loads and returns _that_ specific model from disk. The disk format of the model is always something that the cell understands because it was previously produced and saved to disk by the Cell's train method.\n",
    "\n",
    "In this case the model object is a tf.keras CNN created using the Sequential API. It's on disk representation is a tensorflow SavedModel.\n",
    "\n",
    "**the `_unpack_example` and `_collate_batch` methods**\n",
    "\n",
    "These methods are not part of the `TrainableCell` API and will be discussed in the `train` section.\n",
    "\n",
    "**the `train` method**\n",
    "\n",
    "The `train` method's body looks like a normal deep learning training loop except for some data preparation code. To massage the data from an RVAI Dataset, which contains RVAI typed data (e.g. `rvai.types.Image`, `rvai.types.Integer`, etc. - as described the `Samples` and `Annotations` dataclasses) into something the chosen deep learning framework understands. RVAI provides some compatibility methods to aid this transformation. We use `rvai.base.compat.keras.as_generator` in this case. This function transforms a Dataset into an infinite keras generator. We do have to supply some helper methods though:\n",
    "\n",
    "- `process_example [=cls._unpack_example]` : a method to transform individual Dataset Examples\n",
    "- `process_batch [=cls._collate_batch]` : a method to transform batches of data\n",
    "\n",
    "During a training the cell can send updates about the training process by either a) `yield`-ing `TrainingUpdate`s or by using (in the case of a Keras training loop) a `rvai.base.compat.keras.training_update_callback`, which automatically creates and sends `TrainingUpdate`s.\n",
    "\n",
    "At the end of a training a model path should be returned. It should always point to a trained model on disk.\n",
    "\n",
    "## Creating a Pipeline\n",
    "\n",
    "To start using the `ImageClassificationCell` we build a (single-cell) `Pipeline` with it. Next, we also create a `TrainingPipeline` which defines how the cell should be trained. This is where you would include preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary\n",
    "from rvai.base.pipeline import Pipeline, TrainingPipeline\n",
    "from rvai.base.pipeline.declarative import pipeline\n",
    "\n",
    "# typing\n",
    "from rvai.base.pipeline.declarative import DatasetAnnotations, DatasetSamples, PipelineCells, PipelineInputs, PipelineOutputs, PipelineConnections, TrainingPipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "class ImageClassificationTrainingPipeline(TrainingPipeline):\n",
    "    \n",
    "    # this class does not have to be inline\n",
    "    class TrainingCells(PipelineCells): \n",
    "        classifier: ImageClassificationCell\n",
    "    \n",
    "    cells: TrainingCells\n",
    "    train: ImageClassificationCell = cells.classifier # this attribute marks which cell you want to train with this training pipeline\n",
    "    samples: DatasetSamples = (cells.classifier.samples.image,)\n",
    "    annotations: DatasetAnnotations = (cells.classifier.annotations.label,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "class ImageClassificationPipeline(Pipeline):\n",
    "    \n",
    "    # this class does not have to be inline\n",
    "    class InferenceCells(PipelineCells):\n",
    "        classifier: ImageClassificationCell\n",
    "    \n",
    "    cells: InferenceCells\n",
    "    inputs: PipelineInputs = ((\"image\", cells.classifier.inputs.image),)\n",
    "    outputs: PipelineOutputs = ((\"label\", cells.classifier.outputs.label),)\n",
    "    training_pipelines: TrainingPipelines = (\n",
    "        (cells.classifier, ImageClassificationTrainingPipeline),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Pipelines\n",
    "\n",
    "WIP, visualization of pipelines is very crude at the moment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline = ImageClassificationPipeline()\n",
    "training_pipeline = inference_pipeline.get_training_pipeline(inference_pipeline.cells.classifier)\n",
    "inference_pipeline.show()\n",
    "training_pipeline.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Finally we start the training process on the debug runtime.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In order to train our cell we also need a Dataset of course. An RVAI compatible Dataset requires two methods to be implemented `__getitem__` and `__len__` (cfr. a [pytorch Dataset](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class)). In this tutorial we will use [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required RVAI base class\n",
    "from rvai.base.data import Dataset\n",
    "\n",
    "# used for typing\n",
    "from rvai.types import Image, Integer\n",
    "from typing import Sequence, Tuple\n",
    "import numpy as np\n",
    "\n",
    "# actual data\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# some imports for displaying data\n",
    "from IPython.display import display, HTML\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTDataset(\n",
    "    Dataset[ImageClassificationSamples, ImageClassificationAnnotations]\n",
    "):\n",
    "    def __init__(\n",
    "        self, images: Sequence[np.ndarray], labels: Sequence[np.ndarray]\n",
    "    ):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(\n",
    "        self, index\n",
    "    ) -> Tuple[ImageClassificationSamples, ImageClassificationAnnotations]:\n",
    "        return (\n",
    "            ImageClassificationSamples(image=Image(self.images[index])),\n",
    "            ImageClassificationAnnotations(label=Integer(self.labels[index])),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "# Class names for FashionMNIST\n",
    "class_names = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "\n",
    "train_dataset, validation_dataset = (FashionMNISTDataset(images=images, labels=labels) for images, labels in fashion_mnist.load_data())\n",
    "\n",
    "# display an example image and its label\n",
    "samples, annotations = train_dataset[0]\n",
    "display(PIL.Image.fromarray(samples.image)); print(class_names[annotations.label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "We only print the progress in this example code, but the returned `TrainingUpdate`s contain some other information as well. For example, all the metrics you have defined in your keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rvai.base.runtime import init, Training\n",
    "from rvai.base.training import Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a runtime, we choose the debug runtime\n",
    "runtime = init(\"debug\")\n",
    "\n",
    "# generate a training pipeline\n",
    "training_pipeline = inference_pipeline.get_training_pipeline(inference_pipeline.cells.classifier)\n",
    "\n",
    "# configure a training task\n",
    "training = Training(\n",
    "    pipeline=training_pipeline,\n",
    "    models={}, # no previous models yet\n",
    "    parameters={\"classifier\": ImageClassificationParameters(epochs=1)}, # defaults are fine for us \n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=validation_dataset,\n",
    ")\n",
    "\n",
    "\n",
    "training_loop = runtime.start_training(training)\n",
    "\n",
    "print('Starting training')\n",
    "for update in training_loop.updates():\n",
    "    print(f\"\\r[{update.progress * 100:.3}%] - accuracy: {update.metrics.values.get('acc')}\", end='')\n",
    "model_path = training_loop.result()\n",
    "print(f'\\nTraining done. Model can be found at: {model_path}')\n",
    "# Stop the training process\n",
    "training_loop.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Now we can evaluate the trained model on a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rvai.base.runtime import CellEvaluation\n",
    "\n",
    "# configure a cell evaluation task\n",
    "cell_evaluation = CellEvaluation(\n",
    "    trainable_cell=training_pipeline.trainable_cell, # we select the cell we have trained\n",
    "    model=model_path, # path to the trained model\n",
    "    parameters=ImageClassificationParameters(), # defaults are fine for us\n",
    "    dataset=validation_dataset, # normally this would be a separate test dataset, but for this tutorial re-using the validation dataset\n",
    ")\n",
    "\n",
    "evaluation_loop = runtime.start_cell_evaluation(cell_evaluation)\n",
    "\n",
    "print('Starting cell evaluation')\n",
    "for update in evaluation_loop.updates():\n",
    "    print(f\"\\r{update}\", end='')\n",
    "result = evaluation_loop.result()\n",
    "print(f'\\nEvaluation done: {result}')\n",
    "# Stop the evaluation loop\n",
    "evaluation_loop.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
